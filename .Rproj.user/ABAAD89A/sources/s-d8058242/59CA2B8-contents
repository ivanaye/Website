---
title: 'Project 2: Modeling, Testing, and Predicting'
author: "Ivana Ye"
date: '2020-05-07'
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: yes
---



<ol style="list-style-type: decimal">
<li>Introduction</li>
</ol>
<p>This dataset is a subset of the 1987 National Indonesia Contracpetive Prevalence Survey, which examines the effect of a womans demographic and socio-economic characteristics on her contraceptive method choice. The samples are married women who were either not pregnant or did not know if they were pregnant at the time of the interview. There are seven variables. The first is the wife’s age, which is a numerical variable measuring the wife’s age. The second is the wife’s education, which is a categorical variable, with levels of low(1), mid-low(2), mid-high(3), and high(4). The third is the husband’s education, which is also a categorical variable, with levels of low(1), mid-low(2), mid-high(3), and high(4). The fourth is the number of children ever born, which is a numerical variable, measuring the number of children born. The fifth is the wife’s religion, which is a binary variable, with levels of Non-Islam(0) and Islam(1). The sixth is the wife’s working status, which is also binary, with levels of working(0) and non-working(1). The seventh is the husband’s occupation, which is categorical, with levels of 1,2,3,4. However, the labels of the respective numbers were not apparent from the description of the dataset that was on the website where I obtained my data. The eighth is the standard of living, which is categorical, with the levels of low(1), mid-low(2), mid-high(3), and high(4). The ninth is media exposure, which is binary, with the levels of good(0) and not good(1). The last variable is the contraceptive method used, which is categorical, with the levels of no-use(1), long-term(2), and short-term(3). The entire dataset has 1,472 observations of each of the variables.</p>
<ol start="2" style="list-style-type: decimal">
<li>MANOVA, ANOVA, Post-Hoc T Tests</li>
</ol>
<pre class="r"><code># relabeling data
cmc &lt;- read.csv(&quot;https://archive.ics.uci.edu/ml/machine-learning-databases/cmc/cmc.data&quot;)
names(cmc)[names(cmc) == &quot;X24&quot;] &lt;- &quot;wifes.age&quot;
names(cmc)[names(cmc) == &quot;X2&quot;] &lt;- &quot;wifes.education&quot;
names(cmc)[names(cmc) == &quot;X3&quot;] &lt;- &quot;husbands.education&quot;
names(cmc)[names(cmc) == &quot;X3.1&quot;] &lt;- &quot;number.of.children.born&quot;
names(cmc)[names(cmc) == &quot;X1&quot;] &lt;- &quot;wifes.religion&quot;
names(cmc)[names(cmc) == &quot;X1.1&quot;] &lt;- &quot;wife.work.status&quot;
names(cmc)[names(cmc) == &quot;X2.1&quot;] &lt;- &quot;husbands.occupation&quot;
names(cmc)[names(cmc) == &quot;X3.2&quot;] &lt;- &quot;standard.of.living&quot;
names(cmc)[names(cmc) == &quot;X0&quot;] &lt;- &quot;media.exposure&quot;
names(cmc)[names(cmc) == &quot;X1.2&quot;] &lt;- &quot;contraceptive.method.used&quot;
cmc &lt;- cmc[c(1, 4, 2, 3, 5, 6, 7, 8, 9, 10)]

# changing variables to factors
cmc$contraceptive.method.used &lt;- factor(cmc$contraceptive.method.used, 
    levels = c(1, 2, 3), labels = c(&quot;No-Use&quot;, &quot;Long-Term&quot;, &quot;Short-Term&quot;))

cmc$standard.of.living &lt;- factor(cmc$standard.of.living, levels = c(1, 
    2, 3, 4), labels = c(&quot;Low&quot;, &quot;Mid-Low&quot;, &quot;Mid-High&quot;, &quot;High&quot;))

cmc$wifes.education &lt;- factor(cmc$wifes.education, levels = c(1, 
    2, 3, 4), labels = c(&quot;Low&quot;, &quot;Mid-Low&quot;, &quot;Mid-High&quot;, &quot;High&quot;))

cmc$husbands.education &lt;- factor(cmc$husbands.education, levels = c(1, 
    2, 3, 4), labels = c(&quot;Low&quot;, &quot;Mid-Low&quot;, &quot;Mid-High&quot;, &quot;High&quot;))

cmc$wife.work.status &lt;- factor(cmc$wife.work.status, levels = c(0, 
    1), labels = c(&quot;Working&quot;, &quot;Not-Working&quot;))

cmc$wifes.religion &lt;- factor(cmc$wifes.religion, levels = c(0, 
    1), labels = c(&quot;Non-Islam&quot;, &quot;Islam&quot;))

cmc$husbands.occupation &lt;- factor(cmc$husbands.occupation, levels = c(1, 
    2, 3, 4), labels = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;))

cmc$media.exposure &lt;- factor(cmc$media.exposure, levels = c(0, 
    1), labels = c(&quot;0&quot;, &quot;1&quot;))

# MANVOA
man &lt;- manova(cbind(wifes.age, number.of.children.born) ~ wifes.education, 
    data = cmc)
summary(man)</code></pre>
<pre><code>## Df Pillai approx F num Df den Df Pr(&gt;F)
## wifes.education 3 0.10735 27.756 6 2936 &lt; 2.2e-16 ***
## Residuals 1468
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code># ANOVAs for each numeric variable from manova
summary.aov(man)</code></pre>
<pre><code>## Response wifes.age :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## wifes.education 3 5744 1914.63 29.959 &lt; 2.2e-16 ***
## Residuals 1468 93819 63.91
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response number.of.children.born :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## wifes.education 3 331.8 110.608 20.667 4.067e-13 ***
## Residuals 1468 7856.5 5.352
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code># Post-Hoc T-Test&#39;s
pairwise.t.test(cmc$wifes.age, cmc$wifes.education, p.adj = &quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  cmc$wifes.age and cmc$wifes.education 
## 
##          Low     Mid-Low Mid-High
## Mid-Low  9.8e-16 -       -       
## Mid-High &lt; 2e-16 0.75    -       
## High     1.1e-08 9.0e-05 6.0e-06 
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(cmc$number.of.children.born, cmc$wifes.education, 
    p.adj = &quot;none&quot;)</code></pre>
<pre><code>##
## Pairwise comparisons using t tests with pooled SD
##
## data: cmc$number.of.children.born and
cmc$wifes.education
##
## Low Mid-Low Mid-High
## Mid-Low 6.1e-05 - -
## Mid-High 7.6e-08 0.1056 -
## High 8.5e-14 2.2e-05 0.0072
##
## P value adjustment method: none</code></pre>
<pre class="r"><code># bonferroni adjustment (1 MANOVA, 2 ANOVAS, 12 t tests (15
# tests))
alpha = 0.05/15

# probability of at least 1 type 1 error.
1 - (0.95^(15))</code></pre>
<pre><code>## [1] 0.5367088</code></pre>
<pre class="r"><code># testing assumptions bivariate density plots
ggplot(cmc, aes(x = wifes.age, y = number.of.children.born)) + 
    geom_point(alpha = 0.5) + geom_density_2d(h = 2) + coord_fixed() + 
    facet_wrap(~wifes.education)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-1-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code># covariance matrices
covmats &lt;- cmc %&gt;% group_by(wifes.education) %&gt;% do(covs = cov(.[1:2]))
for (i in 1:4) {
    print(as.character(covmats$wifes.education[i]))
    print(covmats$covs[i])
}</code></pre>
<pre><code>## [1] &quot;Low&quot;
## [[1]]
##                         wifes.age number.of.children.born
## wifes.age               73.573371                9.889857
## number.of.children.born  9.889857                8.682468
## 
## [1] &quot;Mid-Low&quot;
## [[1]]
##                         wifes.age number.of.children.born
## wifes.age                62.88589               10.907151
## number.of.children.born  10.90715                6.190401
## 
## [1] &quot;Mid-High&quot;
## [[1]]
##                         wifes.age number.of.children.born
## wifes.age                64.45594               10.801706
## number.of.children.born  10.80171                5.475604
## 
## [1] &quot;High&quot;
## [[1]]
##                         wifes.age number.of.children.born
## wifes.age                61.57822                9.212750
## number.of.children.born   9.21275                3.907454</code></pre>
<pre class="r"><code># univariate or multivariate outliers
cmc$wifes.education &lt;- as.factor(cmc$wifes.education)
ggplot(cmc, aes(x = wifes.education, y = wifes.age)) + geom_boxplot()</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-1-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(cmc, aes(x = wifes.education, y = number.of.children.born)) + 
    geom_boxplot()</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-1-3.png" width="768" style="display: block; margin: auto;" /></p>
<p>A one-way MANOVA was conducted to determine the effect of the level of the wife’s education (low, mid-low, mid-high, high) on two dependent variables (wife’s age and number of children born). The assumption of random samples and independent observations was assumed to be met from the dataset. Examination of bivariate density plots for each group revealed stark deparures from multivariate normality. Therefore, normality was violated. Examination of covariance matrices for each group revealed relative homogeneity. The covariance matrices looked pretty iffy (low and high wife education levels looked different). Some univariate and multivariate outliers were evident in the boxplot for number.of.children.born, so the no extreme univariate or multivariate outliers assumption was likely not met. Significant differences were found among the four levels of wife’s education for at least one of the dependent variables, Pillai trace = 0.10735, pseudo F(6, 2936) = 27.756, p &lt; 0.05. After running 2 univariate ANOVAs, both univariate ANOVAs, for wifes age and number of children born, significantly differed by the level of the wife’s education, F(6, 2936) = 29.959, p&lt;0.05 and F(6, 2936) = 20.667, p&lt;0.05, respecitively. Post hoc analysis was performed conducting pairwise comparisons to determine which levels of wife’s education differed in the wife’s age and the number of children born. This was found after adjusting for multiple comparisons (bonferroni alpha= 0.05/15= 0.003333333). I performed 15 hypothesis tests (1 MANOVA, 2 ANOVA’s, and 12 post-hoc t tests). The probability that I have made at least one type I error is 0.5367088. The post-hoc-t test for the wife’s age showed that the wife’s age was significantly different between wife education levels of low and mid-low, low and mid-high, low and high, mid-low and high, and mid-high and high after adjusting for multiple comparisons (bonferroni alpha= 0.003333333). The post-hoc t test for the number of children born showed that the number of children born was significantly different between wife education levels of low and mid-low, low and mid-high, low and high, and mid-low and high after adjusting for multiple comparisons (bonferroni alpha=0.003333333).</p>
<ol start="3" style="list-style-type: decimal">
<li>Randomization Test</li>
</ol>
<pre class="r"><code># obtaining test statistic
set.seed(348)
rand_dist &lt;- vector()

for (i in 1:5000) {
    new &lt;- data.frame(number.of.children.born = sample(cmc$number.of.children.born), 
        wife.work.status = (cmc$wife.work.status))
    rand_dist[i] &lt;- mean(new[new$wife.work.status == &quot;Not-Working&quot;, 
        ]$number.of.children.born) - mean(new[new$wife.work.status == 
        &quot;Working&quot;, ]$number.of.children.born)
}

cmc %&gt;% dplyr::group_by(wife.work.status) %&gt;% dplyr::summarize(means = mean(number.of.children.born)) %&gt;% 
    dplyr::summarise(mean_diff = diff(means))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   mean_diff
##       &lt;dbl&gt;
## 1     0.530</code></pre>
<pre class="r"><code># two-tailed p-value
mean(rand_dist &gt; 0.5298803 | rand_dist &lt; -0.5298803)</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code># plot visualizing the null distribution and the test
# statistic
{
    hist(rand_dist, main = &quot;&quot;, ylab = &quot;&quot;)
    abline(v = 0.5298803, col = &quot;red&quot;)
}</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-2-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>The null: the mean number of children born is the same for working vs. non-working wife’s. The alternative: the mean number of children born is different for working vs. non-working wife’s. With a two-tailed p-value of 0 from my permutation test, this means that there is a 0.02% chance of observing a mean difference as extreme as the one observed in my original data under this randomization distribution. Moreover, there are 0 mean differences (simulated under the null= no true mean differene in number of children born by wife’s work status) that are more extreme than the actual value of +/- 0.5298803. So, if the null were true, it would be rare to get something as big as what I got. The p-value of 0 is less than the alpha value of 0.05, so I can reject the null that working and non-working wife’s have the same number of children on average. When I plot out the random distances, the red line, depicting the test-statistic(0.5298803) can’t even be seen, as the random distances range from -0.4 to 0.4. Therefore, this led to the two-tailed p-value of 0.</p>
<ol start="4" style="list-style-type: decimal">
<li>Linear Regression Model</li>
</ol>
<pre class="r"><code># mean center numeric varibale of wifes age.
cmc$wifeage_c &lt;- cmc$wifes.age - mean(cmc$wifes.age)

# linear regression
cmc$contraceptive.method.used &lt;- relevel(cmc$contraceptive.method.used, 
    ref = &quot;Long-Term&quot;)
cmc_fit &lt;- lm(number.of.children.born ~ wifeage_c * contraceptive.method.used, 
    data = cmc)
summary(cmc_fit)</code></pre>
<pre><code>##
## Call:
## lm(formula = number.of.children.born ~ wifeage_c *
contraceptive.method.used,
## data = cmc)
##
## Residuals:
## Min 1Q Median 3Q Max
## -5.2696 -1.2083 -0.2654 0.9850 9.5574
##
## Coefficients:
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 3.408366 0.109602 31.098 &lt; 2e-16 ***
## wifeage_c 0.179528 0.014294 12.560 &lt; 2e-16 ***
## contraceptive.method.usedNo-Use -0.607999 0.134437
-4.523 6.6e-06 ***
## contraceptive.method.usedShort-Term 0.344120 0.142129
2.421 0.0156 *
## wifeage_c:contraceptive.method.usedNo-Use -0.029476
0.016630 -1.773 0.0765 .
## wifeage_c:contraceptive.method.usedShort-Term -0.005478
0.018911 -0.290 0.7721
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Residual standard error: 1.942 on 1466 degrees of
freedom
## Multiple R-squared: 0.3251, Adjusted R-squared: 0.3228
## F-statistic: 141.2 on 5 and 1466 DF, p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code># plot of regression.
ggplot(cmc, aes(wifeage_c, number.of.children.born, color = contraceptive.method.used)) + 
    geom_point() + geom_smooth(method = &quot;lm&quot;, se = F)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code># check of assumptions normality
resids &lt;- cmc_fit$residuals
shapiro.test(resids)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  resids
## W = 0.96331, p-value &lt; 2.2e-16</code></pre>
<pre class="r"><code># homoskedasticity
library(lmtest)
bptest(cmc_fit)</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  cmc_fit
## BP = 225.85, df = 5, p-value &lt; 2.2e-16</code></pre>
<pre class="r"><code># recompute regression results with robust standard error
coeftest(cmc_fit, vcov = vcovHC(cmc_fit))</code></pre>
<pre><code>##
## t test of coefficients:
##
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 3.4083659 0.0802129 42.4915 &lt; 2.2e-16 ***
## wifeage_c 0.1795283 0.0130173 13.7915 &lt; 2.2e-16 ***
## contraceptive.method.usedNo-Use -0.6079990 0.1175196
-5.1736 2.614e-07 ***
## contraceptive.method.usedShort-Term 0.3441200 0.1258401
2.7346 0.006321 **
## wifeage_c:contraceptive.method.usedNo-Use -0.0294763
0.0165113 -1.7852 0.074431 .
## wifeage_c:contraceptive.method.usedShort-Term -0.0054781
0.0192466 -0.2846 0.775970
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code># proportion of variation in the outcome my model explains=
# R^2 value
summary(cmc_fit)$r.sq</code></pre>
<pre><code>## [1] 0.3250712</code></pre>
<p>The y-intercept coefficient: The predicted number of children born for a wife of average age that has long-term contraceptive use is 3.408366. The wifeage_c coefficient: When controlling for contraceptive method used (contraceptive.method.use=0; long-term contraceptive use=reference group), for every one unit increase in the wife’s age, the number of children born increases by 0.179528. The contraceptive.method.usedNo-Use coefficient: For people with an average wife age, no use of contraceptive methods people have predicted number of children born that is 0.607999 lower than long-term use of contraceptive methods people. The contraceptive.method.usedShort-Term coefficient: For people with an average wife age, short-term use of contraceptive methods people have predicted number of children born that is 0.344120 higher than long-term use of contraceptive methods people. The wifeage_c:contraceptive.method.usedNo-Use co-efficient: The slope for the wife’s age on the number of children born is 0.029476 lower for those with no contraceptive method use compared to those with long-term contraceptive method use. The wifeage_c:contraceptive.method.usedShort-Term coefficient: The slope for the wife’s age on the number of children born is 0.005478 lower for those with short-term contraceptive method use compared to those with long-term contraceptive method use.</p>
<p>The assumption of normality is met. Since the p-value of the shapiro-wilk test (&lt;2.2e-16) is less than the alpha value of 0.05, I fail to reject the null that the true distribution of the residual is normal. The assumption of homoskedasticity is met because the p-value of the Breuch-Pagan test (&lt; 2.2e-16) is less than the alpha value of 0.05, so I fail to reject the null that homoskedasticity is met.</p>
<p>After redoing the regression using heteroskedasticity robust standard errors, the intercept is significant (b= 3.4083659, t= 42.4915, p-value &lt; 2.2e-16). The wifeage_c coefficient: There is a significant effect of the wifes age on the number of children born (b=0.1795283, t=13.7915, p&lt; 2.2e-16). The contraceptive.method.usedNo-Use coefficient: There is a significant difference in the predicted number of children born between average wife age women with no contraceptive use vs. long term contracpetive use (b=-0.6079990, t= -5.1736, p=2.614e-07). The contraceptive.method.usedShort-Term coefficient: There is a significant difference in the predicted number of children born between average wife age women with short-term contraceptive use vs. long-term contracpetive use (b= 0.3441200, t=2.7346, p=0.006321). The wifeage_c:contraceptive.method.usedNo-Use co-efficient: The interaction between average wife’s age and no contraceptive use is not significant (b=-0.0294763, t=-1.7852, p= 0.074431). The wifeage_c:contraceptive.method.usedShort-Term coefficient: The interaction between the average wife’s age and short-term contraceptive use is not significant (b= -0.0054781, t=-0.2846, p=0.775970). After the robust standard errors test, the t-statistic and pvalue for the intercept increased from 31.098 to 42.4915 and from &lt; 2e-16 to &lt; 2.2e-16, respectively. The t-statistic and pvalue for wifeage_c increased from 12.560 to 13.7915 and from &lt; 2e-16 to &lt; 2.2e-16, respectively. The t-statistic and pvalue for contraceptive.method.usedNo-Use decreased from -4.523 to -5.1736 and from 6.6e-06 to 2.614e-07, respectively. The t-statistic for contraceptive.method.usedShort-Term increased from 2.421 to 2.7346, while the pvalue decreased from 0.0156 to 0.006321. The t-statistic and pvalue for wifeage_c:contraceptive.method.usedNo-Use slightly decreased from -1.773 to -1.7852 and from 0.0765 to 0.074431, respectively. The t-statistic and pvalue for wifeage_c:contraceptive.method.usedShort-Term increased from -0.290 to -0.2846 and from 0.7721 to 0.775970, respectively. The standard errors for all the co-efficients decreased except for the wifeage_c:contraceptive.method.usedShort-Term coefficient, which had an increase in standard error.</p>
<p>32.50712% of the total variation in the number of children born can be explained by my model.</p>
<ol start="5" style="list-style-type: decimal">
<li>Bootstrapped Standard Errors</li>
</ol>
<pre class="r"><code>set.seed(348)

boot_dat &lt;- sample_frac(cmc, replace = T)

set.seed(348)
samp_distn &lt;- replicate(5000, {
    boot_dat &lt;- cmc[sample(nrow(cmc), replace = TRUE), ]
    cmc_fit2 &lt;- lm(number.of.children.born ~ wifeage_c * contraceptive.method.used, 
        data = boot_dat)
    coef(cmc_fit2)
})

# estimated SE&#39;s
samp_distn %&gt;% t %&gt;% as.data.frame %&gt;% summarize_all(sd)</code></pre>
<pre><code>## (Intercept) wifeage_c contraceptive.method.usedNo-Use
contraceptive.method.usedShort-Term
## 1 0.08025598 0.01286853 0.117276 0.123477
## wifeage_c:contraceptive.method.usedNo-Use
wifeage_c:contraceptive.method.usedShort-Term
## 1 0.01634027 0.01884116</code></pre>
<p>After computing bootstrapped standard errors (SE’s) by resampling rows with replacement from the same regression model above, the bootstrapped SE for the y-intercept is 0.08025598, which is a decrease from the original SE of 0.109602(decrease in p-value as well) and a slight increase from the robust SE of 0.0802129(increase in p-value as well). The bootstrapped SE for wifeage_c is 0.01286853, which is a decrease from the original SE of 0.014294 (decrease in p-value too) as well as a decrease from the robust SE of 0.0130173 (decrease in p-value too). The bootstrapped SE for contraceptive.method.usedNo-Use is 0.117276, which is a decrease from the original SE of 0.134437(decrease in p-value as well) and a slight decrease from the robust SE of 0.1175196 (decrease in p-value as well). The bootstrapped SE for contraceptive.method.usedShort-Term is 0.123477, which is a decrease from the original SE of 0.142129 (decrease in p-value too) and a slight decrease from the robust SE of 0.1258401 (decrease in p-value too). The bootstrapped SE for wifeage_c:contraceptive.method.usedNo-Use is 0.01634027, which is a slight decrease from the original SE of 0.016630 (decrease in p-value as well) and a slight decrease from the robust SE of 0.0165113 (decrease in p-value as well). The bootstrapped SE for wifeage_c:contraceptive.method.usedShort-Term is 0.01884116, which is a slight decrease from the original SE of 0.018911 (decrease in p-value as well) and a decrease from the robust SE of 0.0192466 (decrease in p-value as well).</p>
<ol start="6" style="list-style-type: decimal">
<li>Logistic Regression</li>
</ol>
<pre class="r"><code># create dichotomous outcome variable y(1= not good, 0=good)
cmc &lt;- cmc %&gt;% mutate(y = ifelse(media.exposure == &quot;1&quot;, 1, 0))

# logistic regression
fit33 &lt;- glm(y ~ wifes.religion + standard.of.living, data = cmc, 
    family = &quot;binomial&quot;)
coeftest(fit33)</code></pre>
<pre><code>##
## z test of coefficients:
##
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -1.52152 0.43218 -3.5206 0.0004306 ***
## wifes.religionIslam 0.29416 0.38996 0.7543 0.4506444
## standard.of.livingMid-Low -0.30792 0.27365 -1.1252
0.2604841
## standard.of.livingMid-High -1.66550 0.30462 -5.4674
4.567e-08 ***
## standard.of.livingHigh -2.32373 0.32394 -7.1734
7.317e-13 ***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code># odds
exp(coef(fit33)) %&gt;% round(3) %&gt;% t</code></pre>
<pre><code>## (Intercept) wifes.religionIslam
standard.of.livingMid-Low standard.of.livingMid-High
## [1,] 0.218 1.342 0.735 0.189
## standard.of.livingHigh
## [1,] 0.098</code></pre>
<pre class="r"><code># confusion matrix
cmc &lt;- cmc %&gt;% mutate(prob = predict(fit33, type = &quot;response&quot;), 
    prediction = ifelse(prob &gt; 0.5, 1, 0))
classify33 &lt;- cmc %&gt;% transmute(prob, prediction, truth = y)
head(classify33)</code></pre>
<pre><code>##         prob prediction truth
## 1 0.02789286          0     0
## 2 0.02789286          0     0
## 3 0.05250761          0     0
## 4 0.17722165          0     0
## 5 0.05250761          0     0
## 6 0.17722165          0     0</code></pre>
<pre class="r"><code>table(prediction = classify33$prediction, truth = classify33$truth) %&gt;% 
    addmargins()</code></pre>
<pre><code>##           truth
## prediction    0    1  Sum
##        0   1363  109 1472
##        Sum 1363  109 1472</code></pre>
<pre class="r"><code># accuracy
(1363 + 0)/1472</code></pre>
<pre><code>## [1] 0.9259511</code></pre>
<pre class="r"><code># sensitivity (TPR)
0/109</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code># specificity (TNR)
1363/1363</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code># density of log-odds plot by media exposure
cmc$logit &lt;- predict(fit33, type = &quot;link&quot;)  #get predicted logit scores (logodds)

cmc %&gt;% ggplot() + geom_density(aes(logit, color = media.exposure, 
    fill = media.exposure), alpha = 0.4) + theme(legend.position = c(0.85, 
    0.85)) + geom_vline(xintercept = 0) + xlab(&quot;predictor (logit)&quot;)</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-5-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code># ROC plot
library(plotROC)
ROCplot &lt;- ggplot(classify33) + geom_roc(aes(d = truth, m = prob), 
    n.cuts = 0)
ROCplot</code></pre>
<p><img src="/project2_files/figure-html/unnamed-chunk-5-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code># AUC
calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.7465924</code></pre>
<pre class="r"><code># 10 fold CV
set.seed(1234)
k = 10

cmcdata &lt;- cmc %&gt;% sample_frac  #put rows of dataset in random order
folds &lt;- ntile(1:nrow(cmcdata), n = 10)  #create fold labels (create 10 equal groups)

diags &lt;- NULL
for (i in 1:k) {
    train &lt;- cmcdata[folds != i, ]  #create training set (all but fold i)
    test &lt;- cmcdata[folds == i, ]  #create test set (just fold i)
    truth &lt;- test$y  #save truth labels from fold i
    
    fit33 &lt;- glm(y ~ wifes.religion + standard.of.living, data = train, 
        family = &quot;binomial&quot;)
    probs33 &lt;- predict(fit33, newdata = test, type = &quot;response&quot;)
    
    diags &lt;- rbind(diags, class_diag(probs33, truth))
}

summarize_all(diags, mean)</code></pre>
<pre><code>##         acc sens spec ppv       auc
## 1 0.9259698    0    1 NaN 0.7238115</code></pre>
<p>Interpretation of intercept:The odds of not good media exposure for wife’s that are Non-Islam with a low standard of living is 0.218 (significant; pvalue 0.0004306&lt; alpha of 0.05). Interpretation of co-efficient for wifes.religionIslam: Controlling for standard of living, the predicted odds of not good media exposure for wife’s that are Islam is 1.342 times the odds for wife’s that are Non-Islam (34.2% increase)(non-significant; p-value 0.4506444&gt; alpha of 0.05). Interpretation of co-efficient for standard.of.livingMid-Low: Controlling for wife’s religion, the predicted odds of not good media exposure for a person that has a mid-low standard of living is 0.735 times the odds for a person that has a low standard of living (26.5% decrease)(non-significant; p-value 0.2604841 &gt; alpha of 0.05). Interpretation of co-efficient for standard.of.livingMid-High: Controlling for wife’s religion, the predicted odds of not good media exposure for a person that has a mid-high standard of living is 0.189 times the odds for a person that has a low standard of living (81.1% decrease)(significant; p-value 4.567e-08&lt; alpha of 0.05). Interpretation of co-efficient for standard.of.livingHigh: Controlling for wife’s religion, the predicted odds of not good media exposure for a person that has a high standard of living is 0.098 times the odds for a person that has a low standard of living (90.2% decrease)(significant; p-value 7.317e-13&lt; alpha of 0.05).</p>
<p>The accuracy of the model is 0.9259511, which means that the proportion of correctly predicted amount of media exposure is 0.9259511. The TPR is 0, which means the proportion of not good media exposure correctly predicted was 0. There are no true positives because the model predicts no one that has not good media exposure. The TNR is 1, which means the proportion of good media exposure correctly predicted was 1. There are all true negatives because the model predicts that everyone has good media exposure. The ppv(positive predicted value) is not applicable because there is no one predicted as having not good media exposure.</p>
<p>The AUC of 0.7465924 is fair. Interpretation of the AUC: the probability that a randomly selected person that has not good media exposure (y=1) has a higher predicted probability than a randomly selected person that has good media exposure (y=0) is 0.7465924.</p>
<p>Aftering doing the 10-fold CV on my model, the average out-of-sample accuracy, sensitivity, recall, and AUC are: 0.9259698, 0, NaN,and 0.7334982 respectively.</p>
<ol start="7" style="list-style-type: decimal">
<li>Lasso Regression</li>
</ol>
<pre class="r"><code># LASSO Regression.
library(glmnet)
set.seed(1234)
cmc5 &lt;- cmc %&gt;% dplyr::select(-logit, -prob, -prediction, -media.exposure, 
    -wifeage_c)

fit34 &lt;- glm(y ~ -1 + ., data = cmc5, family = &quot;binomial&quot;)

x &lt;- model.matrix(fit34)
head(x)</code></pre>
<pre><code>## wifes.age number.of.children.born wifes.educationLow
wifes.educationMid-Low
## 1 45 10 1 0
## 2 43 7 0 1
## 3 42 9 0 0
## 4 36 8 0 0
## 5 19 0 0 0
## 6 38 6 0 1
## wifes.educationMid-High wifes.educationHigh
husbands.educationMid-Low husbands.educationMid-High
## 1 0 0 0 1
## 2 0 0 0 1
## 3 1 0 1 0
## 4 1 0 0 1
## 5 0 1 0 0
## 6 0 0 0 1
## husbands.educationHigh wifes.religionIslam
wife.work.statusNot-Working husbands.occupation2
## 1 0 1 1 0
## 2 0 1 1 0
## 3 0 1 1 0
## 4 0 1 1 0
## 5 1 1 1 0
## 6 0 1 1 0
## husbands.occupation3 husbands.occupation4
standard.of.livingMid-Low standard.of.livingMid-High
## 1 1 0 0 0
## 2 1 0 0 0
## 3 1 0 0 1
## 4 1 0 1 0
## 5 1 0 0 1
## 6 1 0 1 0
## standard.of.livingHigh contraceptive.method.usedNo-Use
contraceptive.method.usedShort-Term
## 1 1 1 0
## 2 1 1 0
## 3 0 1 0
## 4 0 1 0
## 5 0 1 0
## 6 0 1 0</code></pre>
<pre class="r"><code>x &lt;- scale(x)  #these are predictors 
y &lt;- as.matrix(cmc5$y)  #response variables. 

cv34 &lt;- cv.glmnet(x, y, family = &quot;binomial&quot;)
lasso34 &lt;- glmnet(x, y, family = &quot;binomial&quot;, lambda = cv34$lambda.1se)
coef(lasso34)</code></pre>
<pre><code>## 20 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                                              s0
## (Intercept)                         -2.86008882
## wifes.age                            .         
## number.of.children.born              0.01425604
## wifes.educationLow                   0.58368901
## wifes.educationMid-Low               .         
## wifes.educationMid-High              .         
## wifes.educationHigh                 -0.09985902
## husbands.educationMid-Low            0.14997412
## husbands.educationMid-High           .         
## husbands.educationHigh              -0.02922889
## wifes.religionIslam                  .         
## wife.work.statusNot-Working          .         
## husbands.occupation2                 .         
## husbands.occupation3                 .         
## husbands.occupation4                 .         
## standard.of.livingMid-Low            0.14507439
## standard.of.livingMid-High           .         
## standard.of.livingHigh              -0.13926117
## contraceptive.method.usedNo-Use      0.04491222
## contraceptive.method.usedShort-Term  .</code></pre>
<pre class="r"><code># 10 fold CV on LASSO
cmc6 &lt;- cmc5
cmc6$wifeseducationLow &lt;- ifelse(cmc6$wifes.education == &quot;Low&quot;, 
    1, 0)
cmc6$wifeseducationHigh &lt;- ifelse(cmc6$wifes.education == &quot;High&quot;, 
    1, 0)
cmc6$husbandseducationMidLow &lt;- ifelse(cmc6$husbands.education == 
    &quot;Mid-Low&quot;, 1, 0)
cmc6$husbandseducationHigh &lt;- ifelse(cmc6$husbands.education == 
    &quot;High&quot;, 1, 0)
cmc6$standardoflivingMidLow &lt;- ifelse(cmc6$standard.of.living == 
    &quot;Mid-Low&quot;, 1, 0)
cmc6$standardoflivingHigh &lt;- ifelse(cmc6$standard.of.living == 
    &quot;High&quot;, 1, 0)
cmc6$contracpetivenouse &lt;- ifelse(cmc6$contraceptive.method.used == 
    &quot;No-Use&quot;, 1, 0)
cmc_data6 &lt;- cmc6 %&gt;% sample_frac  #put rows of dataset in random order
folds &lt;- ntile(1:nrow(cmc_data6), n = 10)  #create fold labels (create 10 equal groups)

diags &lt;- NULL
for (i in 1:k) {
    train6 &lt;- cmc_data6[folds != i, ]  #create training set (all but fold i)
    test6 &lt;- cmc_data6[folds == i, ]  #create test set (just fold i)
    truth6 &lt;- test6$y  #save truth labels from fold i
    
    fit6 &lt;- glm(y ~ number.of.children.born + wifeseducationLow + 
        wifeseducationHigh + husbandseducationMidLow + husbandseducationHigh + 
        standardoflivingMidLow + standardoflivingHigh, data = train6, 
        family = &quot;binomial&quot;)
    probs6 &lt;- predict(fit6, newdata = test6, type = &quot;response&quot;)
    
    diags &lt;- rbind(diags, class_diag(probs6, truth6))
}

summarize_all(diags, mean)</code></pre>
<pre><code>##         acc      sens      spec ppv       auc
## 1 0.9218606 0.1382604 0.9846956 NaN 0.8530784</code></pre>
<p>The non-zero co-efficient estimates are: number.of.children.born, wifeseducationLow, wifeseducationHigh, husbandseducationMidLow, husbandseducationHigh, standardoflivingMidLow, standardoflivingHigh, and contraceptive.method.usedNo-Use. In other words, these are the variables retained. After performing the 10-fold CV using this model, this model’s out of sample accuracy and AUC are 0.9218606 and 0.6371738, respectively. Both of them are lower than that of my logistic model in part 5, which were 0.9259698 (accuracy) and 0.7334982(AUC), respectively.</p>
<p>Note that the <code>echo = FALSE</code> parameter was added to the code chunk to prevent printing of the R code that generated the plot.</p>
